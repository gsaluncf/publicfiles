{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "name": "Pub/Sub Lab: From Queues to Auditors"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pub/Sub Lab: From Queues to Auditors\n",
    "\n",
    "Welcome to the hands-on lab for Week 4. Over the next several sections, you will build\n",
    "a working publish-subscribe system using Amazon Web Services (AWS), and then watch it\n",
    "break in instructive ways.\n",
    "\n",
    "**What you will learn:**\n",
    "- How message queues work (Amazon SQS)\n",
    "- How publish-subscribe (pub/sub) decouples publishers from subscribers (Amazon SNS)\n",
    "- How to define and publish structured events\n",
    "- What happens when messaging is unreliable\n",
    "- Why multiple auditors disagree, and how to resolve it\n",
    "\n",
    "**How this notebook works:**\n",
    "- Read the explanations carefully. They replace a textbook chapter.\n",
    "- Run each code cell **in order** â€” later cells depend on earlier ones.\n",
    "- Helper functions are defined once and reused throughout. Do not skip the setup cells.\n",
    "- When you see **\"Your Turn\"** or **\"Question\"**, stop and think before moving on.\n",
    "\n",
    "> This lab uses real AWS services. Every message you send costs fractions of a cent.\n",
    "> Be thoughtful, but don't worry about cost â€” the entire lab costs less than a dollar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimated time:** 60-90 minutes\n",
    "\n",
    "**By the end of this lab you will be able to:**\n",
    "1. Explain the difference between point-to-point messaging and publish-subscribe\n",
    "2. Send and receive messages using Amazon SQS queues\n",
    "3. Publish events to an SNS topic and observe fan-out to multiple subscribers\n",
    "4. Define a structured event schema and use it in a real system\n",
    "5. Detect duplicate messages, traffic anomalies, and ordering violations\n",
    "6. Compare independent auditor counts and implement majority voting\n",
    "7. Articulate why a peer-to-peer architecture might replace centralized pub/sub\n",
    "\n",
    "**Prerequisite knowledge:** Basic Python (functions, dicts, loops).\n",
    "No prior AWS experience is required — everything is explained step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "Before we begin, we need two things:\n",
    "1. The `boto3` library â€” the official AWS SDK for Python\n",
    "   ([documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html))\n",
    "2. Your AWS credentials, which your instructor has provided\n",
    "\n",
    "Run the next two cells to get set up."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install the AWS SDK for Python\n",
    "# boto3 docs: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
    "!pip install -q boto3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "# --- FILL IN YOUR CREDENTIALS ---\n",
    "# Your instructor will provide these. They are shared for the class.\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]     = \"\"  # paste your access key\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"  # paste your secret key\n",
    "os.environ[\"AWS_DEFAULT_REGION\"]    = \"us-east-1\"\n",
    "\n",
    "# --- YOUR IDENTITY ---\n",
    "# Enter your first name in lowercase. This determines which queue you read from.\n",
    "MY_NAME = \"\"  # e.g. \"bilge\", \"sam\", \"phin\", \"manuel\", \"bruno\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to AWS\n",
    "\n",
    "[`boto3.client()`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#boto3.session.Session.client)\n",
    "creates a connection to a specific AWS service. We will use two services:\n",
    "\n",
    "| Service | What it does | Think of it as... |\n",
    "|---------|-------------|-------------------|\n",
    "| **SQS** (Simple Queue Service) | Message queues â€” store and retrieve messages | A mailbox |\n",
    "| **SNS** (Simple Notification Service) | Pub/sub topics â€” broadcast messages to many subscribers | A radio station |\n",
    "\n",
    "[SQS Documentation](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html) Â·\n",
    "[SNS Documentation](https://docs.aws.amazon.com/sns/latest/dg/welcome.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from collections import Counter\n",
    "\n",
    "# Connect to AWS services\n",
    "sqs = boto3.client(\"sqs\", region_name=\"us-east-1\")\n",
    "sns = boto3.client(\"sns\", region_name=\"us-east-1\")\n",
    "\n",
    "print(\"Connected to AWS SQS and SNS in us-east-1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "The cell below defines functions we will reuse throughout the entire lab.\n",
    "**Run this cell now** â€” every later section depends on it.\n",
    "\n",
    "Take a moment to read each function. They are short on purpose."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ========================================================\n",
    "# HELPER FUNCTIONS â€” used throughout the entire lab\n",
    "# ========================================================\n",
    "\n",
    "# --- Resource Configuration ---\n",
    "# These are the AWS resources your instructor has already created.\n",
    "\n",
    "TOPIC_ARN = \"arn:aws:sns:us-east-1:194722398367:ds2032-view-events.fifo\"\n",
    "FIFO_MESSAGE_GROUP = \"view-events\"\n",
    "\n",
    "# Tier 1: simple standard queues (Section 1 only -- private, NOT connected to SNS)\n",
    "SIMPLE_QUEUES = {\n",
    "    \"bilge\":  \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-bilge\",\n",
    "    \"sam\":    \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-sam\",\n",
    "    \"phin\":   \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-phin\",\n",
    "    \"manuel\": \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-manuel\",\n",
    "    \"bruno\":  \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-bruno\",\n",
    "    \"gil\":    \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-simple-gil\",\n",
    "}\n",
    "\n",
    "# Tier 2: FIFO queues subscribed to SNS topic (Sections 2-7)\n",
    "STUDENT_QUEUES = {\n",
    "    \"bilge\":  \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-bilge.fifo\",\n",
    "    \"sam\":    \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-sam.fifo\",\n",
    "    \"phin\":   \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-phin.fifo\",\n",
    "    \"manuel\": \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-manuel.fifo\",\n",
    "    \"bruno\":  \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-bruno.fifo\",\n",
    "    \"gil\":    \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-node-gil.fifo\",\n",
    "}\n",
    "\n",
    "AUDITOR_QUEUES = {\n",
    "    \"auditor-a\": \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-auditor-a.fifo\",\n",
    "    \"auditor-b\": \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-auditor-b.fifo\",\n",
    "    \"auditor-c\": \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-auditor-c.fifo\",\n",
    "}\n",
    "\n",
    "CHAOS_QUEUE_URL = \"https://sqs.us-east-1.amazonaws.com/194722398367/ds2032-chaos-observer\"\n",
    "\n",
    "# Validate student name\n",
    "assert MY_NAME in STUDENT_QUEUES, f\"Set MY_NAME to one of: {list(STUDENT_QUEUES.keys())}\"\n",
    "MY_SIMPLE_QUEUE_URL = SIMPLE_QUEUES[MY_NAME]   # Section 1 only\n",
    "MY_QUEUE_URL        = STUDENT_QUEUES[MY_NAME]   # Sections 2-7\n",
    "print(f\"You are: {MY_NAME}\")\n",
    "print(f\"Section 1 queue (simple): {MY_SIMPLE_QUEUE_URL.split('/')[-1]}\")\n",
    "print(f\"Section 2+ queue (FIFO):  {MY_QUEUE_URL.split('/')[-1]}\")\n",
    "\n",
    "\n",
    "# --- Sending Messages ---\n",
    "\n",
    "def send_message(queue_url, body, group_id=\"default\"):\n",
    "    \"\"\"Send a single message to an SQS FIFO queue.\n",
    "\n",
    "    Args:\n",
    "        queue_url: The URL of the SQS queue.\n",
    "        body: A dict that will be JSON-serialized.\n",
    "        group_id: FIFO message group (messages in the same group are ordered).\n",
    "\n",
    "    Returns:\n",
    "        The SQS response dict.\n",
    "\n",
    "    Docs: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_SendMessage.html\n",
    "    \"\"\"\n",
    "    return sqs.send_message(\n",
    "        QueueUrl=queue_url,\n",
    "        MessageBody=json.dumps(body),\n",
    "        MessageGroupId=group_id,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def send_direct(queue_url, body):\n",
    "    \"\"\"Send a message to a standard (non-FIFO) SQS queue.\n",
    "\n",
    "    Used in Section 1 with MY_SIMPLE_QUEUE_URL.\n",
    "    No MessageGroupId or deduplication needed.\n",
    "    \"\"\"\n",
    "    return sqs.send_message(\n",
    "        QueueUrl=queue_url,\n",
    "        MessageBody=json.dumps(body),\n",
    "    )\n",
    "\n",
    "def publish_to_topic(message, topic_arn=TOPIC_ARN, group_id=FIFO_MESSAGE_GROUP):\n",
    "    \"\"\"Publish a message to the SNS FIFO topic (broadcast to all subscribers).\n",
    "\n",
    "    Args:\n",
    "        message: A dict that will be JSON-serialized.\n",
    "        topic_arn: The ARN of the SNS topic.\n",
    "        group_id: FIFO message group for ordering.\n",
    "\n",
    "    Returns:\n",
    "        The SNS response dict.\n",
    "\n",
    "    Docs: https://docs.aws.amazon.com/sns/latest/api/API_Publish.html\n",
    "    \"\"\"\n",
    "    return sns.publish(\n",
    "        TopicArn=topic_arn,\n",
    "        Message=json.dumps(message),\n",
    "        MessageGroupId=group_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Receiving Messages ---\n",
    "\n",
    "def receive_messages(queue_url, max_messages=10, wait_seconds=5, delete=True):\n",
    "    \"\"\"Receive messages from an SQS queue.\n",
    "\n",
    "    Args:\n",
    "        queue_url: The URL of the SQS queue.\n",
    "        max_messages: Max messages per batch (1-10).\n",
    "        wait_seconds: Long polling wait time (0-20).\n",
    "        delete: If True, delete messages after receiving (acknowledge them).\n",
    "\n",
    "    Returns:\n",
    "        A list of parsed message body dicts.\n",
    "\n",
    "    Docs: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ReceiveMessage.html\n",
    "    \"\"\"\n",
    "    resp = sqs.receive_message(\n",
    "        QueueUrl=queue_url,\n",
    "        MaxNumberOfMessages=min(max_messages, 10),\n",
    "        WaitTimeSeconds=wait_seconds,\n",
    "    )\n",
    "    results = []\n",
    "    for m in resp.get(\"Messages\", []):\n",
    "        body = json.loads(m[\"Body\"])\n",
    "        results.append(body)\n",
    "        if delete:\n",
    "            sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=m[\"ReceiptHandle\"])\n",
    "    return results\n",
    "\n",
    "\n",
    "def receive_all(queue_url, max_total=200, timeout=30, delete=True):\n",
    "    \"\"\"Receive ALL available messages from a queue (multiple batches).\n",
    "\n",
    "    Keeps reading until the queue is empty or limits are reached.\n",
    "\n",
    "    Args:\n",
    "        queue_url: The URL of the SQS queue.\n",
    "        max_total: Stop after this many messages.\n",
    "        timeout: Stop after this many seconds.\n",
    "        delete: If True, delete messages after receiving.\n",
    "\n",
    "    Returns:\n",
    "        A list of parsed message body dicts.\n",
    "    \"\"\"\n",
    "    all_msgs = []\n",
    "    start = time.time()\n",
    "    while len(all_msgs) < max_total and (time.time() - start) < timeout:\n",
    "        batch = receive_messages(queue_url, max_messages=10, wait_seconds=3, delete=delete)\n",
    "        if not batch:\n",
    "            break\n",
    "        all_msgs.extend(batch)\n",
    "    return all_msgs\n",
    "\n",
    "\n",
    "def drain_queue(queue_url):\n",
    "    \"\"\"Remove all messages from a queue. Returns the count of drained messages.\"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        batch = receive_messages(queue_url, max_messages=10, wait_seconds=1, delete=True)\n",
    "        if not batch:\n",
    "            break\n",
    "        count += len(batch)\n",
    "    return count\n",
    "\n",
    "\n",
    "# --- ViewEvent Creation ---\n",
    "\n",
    "def create_view_event(host_id, content_id, ad_id):\n",
    "    \"\"\"Create a ViewEvent dict with a unique ID and current timestamp.\n",
    "\n",
    "    This is the standard event format for the 2032 system.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"event_id\": str(uuid.uuid4()),\n",
    "        \"host_id\": host_id,\n",
    "        \"content_id\": content_id,\n",
    "        \"ad_id\": ad_id,\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Analysis ---\n",
    "\n",
    "def count_by(events, field):\n",
    "    \"\"\"Count events by a given field. Returns a Counter.\"\"\"\n",
    "    return Counter(e.get(field, \"?\") for e in events)\n",
    "\n",
    "\n",
    "def summarize_events(events, title=\"Event Summary\"):\n",
    "    \"\"\"Print a summary of events by host, content, and ad.\"\"\"\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    print(f\"Total events: {len(events)}\")\n",
    "    for field, label in [(\"host_id\", \"By host\"), (\"content_id\", \"By content\"), (\"ad_id\", \"By ad\")]:\n",
    "        counts = count_by(events, field)\n",
    "        print(f\"\\n  {label}:\")\n",
    "        for val, cnt in counts.most_common():\n",
    "            print(f\"    {val}: {cnt}\")\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 1: I Can Talk Using Queues\n",
    "\n",
    "## What is a message queue?\n",
    "\n",
    "A **message queue** is one of the simplest building blocks in distributed systems.\n",
    "It works exactly like it sounds:\n",
    "\n",
    "1. A **sender** puts a message into the queue.\n",
    "2. The message sits there until someone picks it up.\n",
    "3. A **receiver** reads the message and processes it.\n",
    "4. The receiver **deletes** the message to confirm it was handled.\n",
    "\n",
    "This pattern decouples the sender from the receiver. The sender does not need to know\n",
    "*who* will read the message, or *when*. It just drops the message and moves on.\n",
    "\n",
    "## Amazon SQS\n",
    "\n",
    "[Amazon SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)\n",
    "is a managed message queue service. We are starting with a **standard queue** — the simplest kind.\n",
    "It gives you the core send/receive/delete model without extra complexity.\n",
    "\n",
    "In Section 2 we will upgrade to **FIFO queues** which add two guarantees:\n",
    "1. **Ordering**: Messages come out in the order they went in.\n",
    "2. **Exactly-once delivery**: Duplicate message bodies won’t slip through.\n",
    "\n",
    "> Your Section 1 queue is `{MY_SIMPLE_QUEUE_URL.split('/')[-1]}`.\n",
    "> It is **private** — not connected to any SNS topic. Only you send and receive here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A: Send a message\n",
    "\n",
    "Let's start simple. We will send a single message to your queue and then read it back."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1A: Send a single message to YOUR queue\n",
    "\n",
    "message = {\"greeting\": \"Hello from the queue!\", \"sender\": MY_NAME}\n",
    "\n",
    "response = send_direct(MY_SIMPLE_QUEUE_URL, message)\n",
    "\n",
    "print(f\"SENT: {json.dumps(message)}\")\n",
    "print(f\"  MessageId:      {response['MessageId']}\")\n",
    "print(f\"  (No SequenceNumber -- that only exists on FIFO queues)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MessageId` is assigned by SQS â€” it is the queue's receipt for your message.\n",
    "The `SequenceNumber` exists because this is a FIFO queue; it tells you where\n",
    "your message falls in the total ordering.\n",
    "\n",
    "Now let's read it back."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1A: Receive the message from YOUR queue\n",
    "\n",
    "time.sleep(1)  # Brief pause to let the message arrive\n",
    "\n",
    "received = receive_messages(MY_SIMPLE_QUEUE_URL, max_messages=1, wait_seconds=5)\n",
    "\n",
    "if received:\n",
    "    print(f\"RECEIVED: {json.dumps(received[0])}\")\n",
    "    print(f\"\\nThe message was automatically deleted after reading (delete=True).\")\n",
    "else:\n",
    "    print(\"No message received. The queue might be empty.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `receive_messages` **deleted** the message after reading it.\n",
    "This is important. In SQS, reading a message does not remove it.\n",
    "Deletion is a separate, explicit step â€” our helper function handles it for you.\n",
    "\n",
    "**Why does deletion exist?** Because reading might fail. If your code crashes\n",
    "after reading but before processing, the message should come back so someone\n",
    "else can try. This is called **at-least-once delivery**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Send a custom message\n",
    "\n",
    "Modify the code below to send a message with your own content.\n",
    "Try including different data types — a number, a list, a boolean.\n",
    "What happens when you receive it back?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR TURN: Send your own custom message\n",
    "# Change the message content to whatever you want.\n",
    "\n",
    "my_message = {\n",
    "    \"from\": MY_NAME,\n",
    "    # Add your own fields here:\n",
    "    # \"favorite_number\": ???,\n",
    "    # \"languages\": ???,\n",
    "}\n",
    "\n",
    "send_direct(MY_SIMPLE_QUEUE_URL, my_message)\n",
    "time.sleep(1)\n",
    "result = receive_messages(MY_SIMPLE_QUEUE_URL, max_messages=1)\n",
    "if result:\n",
    "    print(\"Got back:\", json.dumps(result[0], indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B: FIFO ordering\n",
    "\n",
    "FIFO means \"first in, first out.\" Let's prove it by sending 10 numbered messages\n",
    "and checking that they arrive in the same order."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1B: Send 10 numbered messages\n",
    "print(\"Sending 10 numbered messages...\")\n",
    "for i in range(1, 11):\n",
    "    send_direct(MY_SIMPLE_QUEUE_URL, {\"sequence\": i, \"label\": f\"Message #{i}\"})\n",
    "    print(f\"  Sent #{i}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1B: Receive them and check order\n",
    "time.sleep(1)\n",
    "\n",
    "received = receive_all(MY_SIMPLE_QUEUE_URL, max_total=10, timeout=15)\n",
    "received_order = [m.get(\"sequence\") for m in received]\n",
    "\n",
    "print(f\"Sent order:     {list(range(1, 11))}\")  # still 10 messages in the loop\n",
    "print(f\"Received order: {received_order}\")\n",
    "print(f\"In order?       {received_order == list(range(1, 11))}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a FIFO queue, messages within the same **message group** are guaranteed\n",
    "to arrive in order. We used `group_id=\"fifo-test\"` for all 10 messages,\n",
    "so they share a group and maintain their sequence.\n",
    "\n",
    "> **Key concept:** Ordering is not free. It requires coordination by the queue\n",
    "> service. Standard (non-FIFO) queues skip this coordination, which makes them\n",
    "> faster but unordered. More on this in Section 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Break the ordering\n",
    "\n",
    "What happens if you send messages to **different message groups**?\n",
    "FIFO ordering is only guaranteed *within* a group. Try it:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR TURN: Send multiple messages and see what arrives\n",
    "# Standard queues don't have message groups -- all messages share one pool.\n",
    "\n",
    "# Clear the queue first\n",
    "drain_queue(MY_SIMPLE_QUEUE_URL)\n",
    "\n",
    "# Send 5 'A' messages and 5 'B' messages alternating\n",
    "for i in range(1, 6):\n",
    "    send_direct(MY_SIMPLE_QUEUE_URL, {\"group\": \"A\", \"seq\": i})\n",
    "    send_direct(MY_SIMPLE_QUEUE_URL, {\"group\": \"B\", \"seq\": i})\n",
    "\n",
    "time.sleep(1)\n",
    "received = receive_all(MY_SIMPLE_QUEUE_URL, max_total=10, timeout=10)\n",
    "\n",
    "print(\"Received order:\")\n",
    "for m in received:\n",
    "    print(f\"  Group {m['group']}, Seq {m['seq']}\")\n",
    "\n",
    "# In Section 2 we'll use FIFO queues where group ordering is guaranteed.\n",
    "# How does the ordering here compare to what you'd expect from FIFO?"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C: What happens if you don't delete?\n",
    "\n",
    "SQS has a feature called **visibility timeout**. When you read a message,\n",
    "it becomes *invisible* to other readers for a set period (default: 30 seconds).\n",
    "If you don't delete it within that window, it reappears â€” as if you never read it.\n",
    "\n",
    "This is *by design*. It prevents messages from being lost if a reader crashes.\n",
    "But it can also cause **double-counting** if you are not careful.\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "> **Note:** This cell takes about 35 seconds to run (it waits for the timeout to expire)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1C: Visibility timeout demo\n",
    "\n",
    "# Send one message\n",
    "send_direct(MY_SIMPLE_QUEUE_URL, {\"purpose\": \"visibility demo\", \"value\": 42})\n",
    "print(\"Sent a message.\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Read it but DO NOT delete it\n",
    "batch = receive_messages(MY_SIMPLE_QUEUE_URL, max_messages=1, wait_seconds=5, delete=False)\n",
    "if batch:\n",
    "    print(f\"Read (1st time): {json.dumps(batch[0])}\")\n",
    "    print(\"  --> NOT deleting this message.\")\n",
    "else:\n",
    "    print(\"No message received.\")\n",
    "\n",
    "# Wait for the visibility timeout to expire (30 seconds)\n",
    "print(f\"\\nWaiting 35 seconds for visibility timeout to expire...\")\n",
    "time.sleep(35)\n",
    "\n",
    "# Read again â€” the same message should reappear\n",
    "batch2 = receive_messages(MY_SIMPLE_QUEUE_URL, max_messages=1, wait_seconds=5, delete=True)\n",
    "if batch2:\n",
    "    print(f\"Read (2nd time!): {json.dumps(batch2[0])}\")\n",
    "    print(\"  --> The message came BACK because we didn't delete it the first time!\")\n",
    "    print(\"  --> Now deleted for real.\")\n",
    "else:\n",
    "    print(\"Message did not reappear (might have been consumed by another reader).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways from Section 1:**\n",
    "\n",
    "| Concept | What you saw |\n",
    "|---------|-------------|\n",
    "| Message queues | Send, receive, delete â€” three separate operations |\n",
    "| FIFO ordering | Messages arrive in the order they were sent |\n",
    "| Visibility timeout | Undeleted messages reappear after 30 seconds |\n",
    "| At-least-once delivery | The same message *can* be delivered more than once |\n",
    "| Explicit deletion | You must explicitly confirm you handled a message |\n",
    "\n",
    "These properties will matter a lot when we start counting things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Pub/Sub Concepts\n",
    "\n",
    "## From point-to-point to broadcast\n",
    "\n",
    "In Section 1, you sent messages to *your own queue* â€” that is **point-to-point**\n",
    "messaging. One sender, one queue, one receiver.\n",
    "\n",
    "But what if you want to send a message to *many* receivers at once?\n",
    "\n",
    "That is **publish-subscribe** (pub/sub). Instead of sending to a specific queue,\n",
    "you publish to a **topic**. Every queue that is **subscribed** to that topic\n",
    "gets its own copy of the message.\n",
    "\n",
    "## Amazon SNS\n",
    "\n",
    "[Amazon SNS](https://docs.aws.amazon.com/sns/latest/dg/welcome.html) provides\n",
    "managed pub/sub topics. Here is our setup:\n",
    "\n",
    "```\n",
    "  Publisher (you)\n",
    "       |\n",
    "       v\n",
    "  [SNS Topic: ds2032-view-events.fifo]\n",
    "       |         |         |         |       |       |\n",
    "       v         v         v         v       v       v\n",
    "  [bilge]    [sam]    [phin]   [manuel]  [bruno]  [gil]\n",
    "  (SQS)      (SQS)   (SQS)    (SQS)     (SQS)   (SQS)\n",
    "```\n",
    "\n",
    "When you publish **one** message to the topic, **all six queues** receive a copy.\n",
    "This is called **fan-out**.\n",
    "\n",
    "The publisher does not know who is subscribed. The subscribers do not know who\n",
    "published. Neither side needs to change when subscribers are added or removed.\n",
    "This is **decoupling** â€” one of the most powerful ideas in distributed systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A: Publish to the topic\n",
    "\n",
    "Let's publish a single message to the SNS topic and see if it arrives in multiple queues.\n",
    "\n",
    "First, we need to drain your queue so we start with a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2A: Clean start\n",
    "drained = drain_queue(MY_QUEUE_URL)\n",
    "print(f\"Drained {drained} old messages from your queue.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2A: Publish ONE message to the SNS topic\n",
    "\n",
    "message = {\n",
    "    \"demo\": True,\n",
    "    \"content\": \"This is a pub/sub broadcast\",\n",
    "    \"from\": MY_NAME,\n",
    "}\n",
    "\n",
    "response = publish_to_topic(message)\n",
    "print(f\"PUBLISHED to SNS topic:\")\n",
    "print(f\"  Message: {json.dumps(message)}\")\n",
    "print(f\"  MessageId: {response['MessageId']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That message was sent to the **topic**, not to any specific queue.\n",
    "SNS will now deliver a copy to every subscribed queue.\n",
    "\n",
    "Let's check your queue."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2A: Check YOUR queue for the message\n",
    "time.sleep(2)\n",
    "\n",
    "received = receive_messages(MY_QUEUE_URL, max_messages=1, wait_seconds=5)\n",
    "if received:\n",
    "    print(f\"YOUR queue received: {json.dumps(received[0])}\")\n",
    "else:\n",
    "    print(\"Nothing in your queue yet. Try running this cell again after a moment.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your queue got the message â€” but so did everyone else's queue.\n",
    "One publish, six copies. That is fan-out.\n",
    "\n",
    "### 2B: Fan-out at scale\n",
    "\n",
    "Let's make this more convincing. We will publish 5 messages and then check\n",
    "multiple queues to confirm each one got all 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Predict before you run\n",
    "\n",
    "Before running the next cell, **write down your prediction**:\n",
    "- If you publish 5 messages to the SNS topic, and there are 6 student queues\n",
    "  plus 3 auditor queues subscribed... how many total message copies will exist\n",
    "  across all queues?\n",
    "\n",
    "Think about it, write your answer, then run the cell to check."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2B: Drain first, then publish 5 messages\n",
    "drain_queue(MY_QUEUE_URL)\n",
    "\n",
    "print(\"Publishing 5 messages to the topic...\")\n",
    "for i in range(1, 6):\n",
    "    msg = {\"sequence\": i, \"label\": f\"broadcast-{i}\", \"from\": MY_NAME}\n",
    "    publish_to_topic(msg)\n",
    "    print(f\"  Published #{i}\")\n",
    "\n",
    "time.sleep(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2B: Read from YOUR queue and count\n",
    "received = receive_all(MY_QUEUE_URL, max_total=10, timeout=10)\n",
    "sequences = [m.get(\"sequence\") for m in received]\n",
    "\n",
    "print(f\"Your queue received: {len(received)} messages\")\n",
    "print(f\"Sequences: {sequences}\")\n",
    "print(f\"\\nEvery subscribed queue gets its own independent copy.\")\n",
    "print(f\"That is fan-out: one publish, many subscribers.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways from Section 2:**\n",
    "\n",
    "| Concept | What you saw |\n",
    "|---------|-------------|\n",
    "| SNS topics | A broadcast channel â€” publish once, deliver to many |\n",
    "| Fan-out | Each subscriber queue gets its own copy |\n",
    "| Decoupling | Publisher and subscribers are independent |\n",
    "| Subscriptions | Queues opt in to a topic; adding/removing does not affect publishers |\n",
    "\n",
    "> **Think about it:** If the publisher does not know who is listening,\n",
    "> and the subscribers do not know who is publishing...\n",
    "> who is in control? Is anyone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: I Am a Host\n",
    "\n",
    "*The year is 2032. The One Persona Act has changed how online advertising works.\n",
    "Content creators â€” \"hosts\" â€” serve content and display ads. They get paid based\n",
    "on verified view counts. But who verifies the views?*\n",
    "\n",
    "**You are a host.** When someone views your content and sees an ad, you need\n",
    "to record that event. You publish a `ViewEvent` so that auditors â€” independent\n",
    "observers â€” can verify the view actually happened.\n",
    "\n",
    "Your livelihood depends on accurate counts. If auditors miss views, you lose money.\n",
    "If they double-count, advertisers overpay. Everyone needs the numbers to be right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A: The ViewEvent schema\n",
    "\n",
    "Every time a view happens, you create a structured event with these fields:\n",
    "\n",
    "| Field | Type | Meaning |\n",
    "|-------|------|---------|\n",
    "| `event_id` | UUID | Unique identifier for this specific view |\n",
    "| `host_id` | string | Who is hosting the content (you) |\n",
    "| `content_id` | string | What content was viewed |\n",
    "| `ad_id` | string | What ad was displayed alongside it |\n",
    "| `timestamp` | ISO 8601 | When the view happened (UTC) |\n",
    "\n",
    "The `event_id` is critical. It is how auditors detect duplicates. Two events\n",
    "with the same `event_id` represent the *same view*, not two separate views."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3A: Create a sample ViewEvent\n",
    "\n",
    "sample = create_view_event(\n",
    "    host_id=MY_NAME,\n",
    "    content_id=\"video-matrix-reloaded\",\n",
    "    ad_id=\"ad-coca-cola-2032\",\n",
    ")\n",
    "\n",
    "print(\"ViewEvent:\")\n",
    "print(json.dumps(sample, indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B: Publishing view events\n",
    "\n",
    "Let's simulate 10 views on your content. In the real system, these would be\n",
    "generated automatically as users watch your videos or read your articles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3B: Simulate 10 views on your content\n",
    "\n",
    "CONTENT_CATALOG = [\n",
    "    (\"video-matrix\", \"ad-pepsi\"),\n",
    "    (\"article-ai-future\", \"ad-nvidia\"),\n",
    "    (\"video-matrix-reloaded\", \"ad-coca-cola-2032\"),\n",
    "    (\"podcast-distributed-sys\", \"ad-aws\"),\n",
    "    (\"article-quantum-2032\", \"ad-google\"),\n",
    "]\n",
    "\n",
    "published_events = []\n",
    "\n",
    "print(f\"Simulating 10 views on host '{MY_NAME}'...\\n\")\n",
    "for i in range(10):\n",
    "    content_id, ad_id = CONTENT_CATALOG[i % len(CONTENT_CATALOG)]\n",
    "    event = create_view_event(MY_NAME, content_id, ad_id)\n",
    "    publish_to_topic(event)\n",
    "    published_events.append(event)\n",
    "    print(f\"  View #{i+1}: {content_id} with {ad_id}\")\n",
    "\n",
    "print(f\"\\nPublished {len(published_events)} ViewEvents.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C: Reading as an auditor\n",
    "\n",
    "Those events went to the SNS topic and were delivered to every subscribed queue.\n",
    "Now let's read from an **auditor queue** â€” a separate queue that exists solely\n",
    "to observe and count events.\n",
    "\n",
    "Think of the auditor as an independent accountant. They watch the event stream\n",
    "and keep their own tally."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3C: Read from an auditor queue\n",
    "time.sleep(2)\n",
    "\n",
    "auditor_events = receive_all(AUDITOR_QUEUES[\"auditor-a\"], max_total=50, timeout=15)\n",
    "\n",
    "print(f\"Auditor A received {len(auditor_events)} events.\\n\")\n",
    "for i, e in enumerate(auditor_events[:10]):  # Show first 10\n",
    "    print(f\"  [{i+1}] host={e.get('host_id')}, content={e.get('content_id')}\")\n",
    "if len(auditor_events) > 10:\n",
    "    print(f\"  ... and {len(auditor_events) - 10} more\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3C: Count and summarize what the auditor saw\n",
    "summarize_events(auditor_events, title=\"Auditor A's View\")\n",
    "\n",
    "# Verify: do the counts match what we published?\n",
    "print(f\"\\n--- Verification ---\")\n",
    "print(f\"You published:     {len(published_events)} events\")\n",
    "my_events = [e for e in auditor_events if e.get('host_id') == MY_NAME]\n",
    "print(f\"Auditor saw yours: {len(my_events)}\")\n",
    "\n",
    "pub_ids = {e['event_id'] for e in published_events}\n",
    "aud_ids = {e.get('event_id') for e in my_events}\n",
    "print(f\"All IDs match:     {pub_ids == aud_ids}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, everything matches. The auditor saw exactly what you published.\n",
    "Every event ID checks out. The count is correct.\n",
    "\n",
    "**But ask yourself:**\n",
    "- What if the auditor missed some events?\n",
    "- What if the same event arrived twice?\n",
    "- What if you had *no* auditor at all?\n",
    "- Who gets the final say on whether a view \"happened\"?\n",
    "\n",
    "We will break these assumptions one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Be a dishonest host\n",
    "\n",
    "What if a host wanted to inflate their view count? They could publish\n",
    "fake ViewEvents with made-up content IDs. Write code to do this —\n",
    "then think about how an auditor would detect it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR TURN: Publish 5 \"fake\" view events\n",
    "# Use a content_id that doesn't exist in the catalog.\n",
    "# Then think: how would an auditor know these are fake?\n",
    "\n",
    "# fake_event = create_view_event(\n",
    "#     host_id=MY_NAME,\n",
    "#     content_id=\"video-DOES-NOT-EXIST\",\n",
    "#     ad_id=\"ad-FAKE\",\n",
    "# )\n",
    "# publish_to_topic(fake_event)\n",
    "# print(\"Published fake event:\", fake_event[\"event_id\"][:12])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint: Section 3\n",
    "\n",
    "1. Why is the `event_id` field important? What would happen without it?\n",
    "2. If you publish 10 events but the auditor only sees 8, whose count is \"correct\"?\n",
    "3. The host creates the event and the timestamp. Can the auditor trust either of those?\n",
    "4. What would prevent a host from publishing millions of fake events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 4: Guarantees and Their Limits\n",
    "\n",
    "So far, everything has worked perfectly. Messages arrived in order. Counts matched.\n",
    "No duplicates. That is because we used **FIFO queues**, which AWS guarantees will:\n",
    "\n",
    "1. Deliver messages in order (within a message group)\n",
    "2. Deduplicate identical messages (within a 5-minute window)\n",
    "\n",
    "But these guarantees come with trade-offs.\n",
    "\n",
    "### FIFO vs. Standard Queues\n",
    "\n",
    "| Property | FIFO Queue | Standard Queue |\n",
    "|----------|-----------|----------------|\n",
    "| Ordering | Guaranteed (within message group) | Best-effort (no guarantee) |\n",
    "| Deduplication | Exactly-once (5-min window) | At-least-once (may duplicate) |\n",
    "| Throughput | 300 messages/sec (3,000 with batching) | Nearly unlimited |\n",
    "| Cost | Higher | Lower |\n",
    "\n",
    "[FIFO queue documentation](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html) Â·\n",
    "[Standard queue documentation](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html)\n",
    "\n",
    "**The trade-off:** FIFO gives you correctness but limits throughput. Standard gives\n",
    "you speed but no ordering or dedup guarantees. Most real-world distributed systems\n",
    "use standard queues and handle ordering/dedup in application code.\n",
    "\n",
    "### Visibility Timeout Revisited\n",
    "\n",
    "You saw in Section 1 that undeleted messages reappear. Here is why this matters\n",
    "for counting: if your auditor reads a message, starts counting it, but crashes\n",
    "before deleting it â€” the message comes back. A second reader counts it again.\n",
    "Now you have a **double count**.\n",
    "\n",
    "This is not a bug. It is a fundamental property of at-least-once delivery.\n",
    "The queue guarantees your message will not be *lost*, but it cannot guarantee\n",
    "it will be delivered only *once*.\n",
    "\n",
    "### How do you handle duplicates?\n",
    "\n",
    "The standard approach is called **idempotent processing**:\n",
    "\n",
    "1. Keep a set of event IDs you have already processed\n",
    "2. When you receive a message, check if you have seen that `event_id` before\n",
    "3. If yes, skip it â€” do not count it again\n",
    "4. If no, process it and add the `event_id` to your set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 4: Idempotent processing demo\n",
    "\n",
    "# Simulate receiving the same events multiple times\n",
    "fake_stream = published_events + published_events[:3]  # 13 messages, 3 are repeats\n",
    "\n",
    "print(f\"Incoming stream: {len(fake_stream)} messages\")\n",
    "\n",
    "# Naive count (no dedup)\n",
    "naive_count = len(fake_stream)\n",
    "print(f\"Naive count (just len): {naive_count}\")\n",
    "\n",
    "# Idempotent count (with dedup)\n",
    "seen_ids = set()\n",
    "deduped = []\n",
    "for event in fake_stream:\n",
    "    eid = event[\"event_id\"]\n",
    "    if eid not in seen_ids:\n",
    "        seen_ids.add(eid)\n",
    "        deduped.append(event)\n",
    "\n",
    "print(f\"Deduplicated count:     {len(deduped)}\")\n",
    "print(f\"Duplicates caught:      {naive_count - len(deduped)}\")\n",
    "print(f\"\\nIdempotent processing prevents double-counting.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Retention and Dead Letter Queues\n",
    "\n",
    "Two more concepts that affect how queues behave in the real world:\n",
    "\n",
    "**Message retention** â€” SQS keeps unread messages for a configurable time\n",
    "(default: 4 days, max: 14 days). After that, they are permanently deleted.\n",
    "([docs](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-basic-architecture.html))\n",
    "\n",
    "If your auditor is offline for a week, those messages are gone. You lost data.\n",
    "\n",
    "**Dead Letter Queues (DLQ)** â€” If a message fails processing repeatedly\n",
    "(e.g., it keeps being received but never deleted), SQS can move it to a\n",
    "separate \"dead letter\" queue for inspection.\n",
    "([docs](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html))\n",
    "\n",
    "This is useful for debugging. Instead of a bad message blocking the queue\n",
    "forever, it gets moved aside so the rest of the queue keeps flowing.\n",
    "\n",
    "> **Your Turn:** Think about what would happen if your 2032 auditor went offline\n",
    "> for longer than the message retention period. Views happened, events were\n",
    "> published, but the auditor never saw them. What happens to your payment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5: I Am Not Alone\n",
    "\n",
    "Up until now, you have been the only host publishing events. Your auditor\n",
    "saw only your events, and everything was clean.\n",
    "\n",
    "But in the real 2032 system, you are one of many hosts. The SNS topic carries\n",
    "events from *all* hosts. Your auditor queue receives *everyone's* events.\n",
    "\n",
    "**Your instructor has started a simulator** that publishes events from\n",
    "multiple simulated hosts. Let's see what your queue looks like now."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 5: Read all events from your queue\n",
    "\n",
    "print(f\"Reading from your queue ({MY_NAME})...\\n\")\n",
    "\n",
    "events = receive_all(MY_QUEUE_URL, max_total=200, timeout=20)\n",
    "\n",
    "print(f\"Total events received: {len(events)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 5: Who is publishing?\n",
    "\n",
    "host_counts = count_by(events, \"host_id\")\n",
    "\n",
    "print(\"Events by host:\\n\")\n",
    "total = len(events) if events else 1\n",
    "for host, count in host_counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    bar = \"#\" * int(pct / 2)\n",
    "    print(f\"  {host:25s}: {count:4d} ({pct:5.1f}%) {bar}\")\n",
    "\n",
    "# How many are yours?\n",
    "my_count = host_counts.get(MY_NAME, 0)\n",
    "print(f\"\\nYour events: {my_count}\")\n",
    "print(f\"Other hosts:  {len(events) - my_count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 5: Full summary\n",
    "summarize_events(events, title=\"Multi-Host Traffic\")\n",
    "\n",
    "# Check ordering\n",
    "from datetime import datetime as dt\n",
    "timestamps = []\n",
    "for e in events:\n",
    "    try:\n",
    "        timestamps.append(dt.fromisoformat(e.get(\"timestamp\", \"\")))\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "\n",
    "out_of_order = sum(1 for i in range(1, len(timestamps)) if timestamps[i] < timestamps[i-1])\n",
    "print(f\"\\nOrdering: {out_of_order} events arrived out of chronological order\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "1. How many different hosts are publishing events?\n",
    "2. Which host has the most traffic? Does that seem proportional?\n",
    "3. If you were auditing only *your own* views, how would you filter\n",
    "   out everyone else's events?\n",
    "4. Could a host fake their own view events to inflate their count?\n",
    "   What would stop them?\n",
    "5. Were events in chronological order? If not, what does that mean\n",
    "   for an auditor that processes events sequentially?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 6: Something Is Wrong\n",
    "\n",
    "Your instructor has set up a second environment â€” this one uses a **standard**\n",
    "(non-FIFO) queue. The chaos scripts have been running. Things that were reliable\n",
    "in the FIFO world no longer hold.\n",
    "\n",
    "In this section, you will read from the chaos queue and see what broke."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 6: Read from the chaos queue\n",
    "\n",
    "print(\"Reading from the chaos queue (standard, non-FIFO)...\\n\")\n",
    "\n",
    "chaos_events = receive_all(CHAOS_QUEUE_URL, max_total=200, timeout=20)\n",
    "\n",
    "print(f\"Total messages received: {len(chaos_events)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 6: Detect duplicates\n",
    "\n",
    "event_id_counts = Counter(e.get(\"event_id\", \"?\") for e in chaos_events)\n",
    "duplicates = {eid: cnt for eid, cnt in event_id_counts.items() if cnt > 1}\n",
    "\n",
    "print(f\"--- Duplicate Detection ---\")\n",
    "print(f\"  Total messages:       {len(chaos_events)}\")\n",
    "print(f\"  Unique event IDs:     {len(event_id_counts)}\")\n",
    "print(f\"  Duplicated event IDs: {len(duplicates)}\")\n",
    "print(f\"  Extra copies:         {len(chaos_events) - len(event_id_counts)}\")\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"\\n  Worst offenders:\")\n",
    "    for eid, cnt in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        print(f\"    {eid[:16]}... appeared {cnt} times\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 6: Detect traffic spikes\n",
    "\n",
    "host_counts = count_by(chaos_events, \"host_id\")\n",
    "total = len(chaos_events) if chaos_events else 1\n",
    "\n",
    "print(f\"--- Traffic Spike Detection ---\\n\")\n",
    "for host, count in host_counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    bar = \"#\" * int(pct / 2)\n",
    "    flag = \"  ** SUSPICIOUS\" if pct > 40 else \"\"\n",
    "    print(f\"  {host:25s}: {count:4d} ({pct:5.1f}%) {bar}{flag}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 6: Detect late events\n",
    "\n",
    "from datetime import timezone as tz\n",
    "\n",
    "now = datetime.now(tz.utc)\n",
    "late = []\n",
    "for e in chaos_events:\n",
    "    try:\n",
    "        ts = datetime.fromisoformat(e.get(\"timestamp\", \"\"))\n",
    "        age = (now - ts).total_seconds()\n",
    "        if age > 300:  # older than 5 minutes\n",
    "            late.append({\"host\": e.get(\"host_id\"), \"age_min\": age / 60, \"eid\": e[\"event_id\"][:16]})\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "\n",
    "print(f\"--- Late Event Detection ---\")\n",
    "print(f\"  Events older than 5 minutes: {len(late)}\")\n",
    "for l in late[:5]:\n",
    "    print(f\"    {l['eid']}... from {l['host']}, claimed {l['age_min']:.0f} min ago\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What broke and why:**\n",
    "\n",
    "| Problem | Cause | What it breaks |\n",
    "|---------|-------|---------------|\n",
    "| Duplicate events | Same event published twice + standard queue does not deduplicate | Count inflation |\n",
    "| Traffic spike | One host flooding the topic | Proportionality assumptions |\n",
    "| Late timestamps | Events claim to be from 30 minutes ago | Temporal ordering, windowed counting |\n",
    "| Out-of-order arrival | Standard queues do not guarantee ordering | Sequential processing logic |\n",
    "\n",
    "**The bottom line:** If you are building an auditor, you cannot blindly trust:\n",
    "- Message counts (duplicates exist)\n",
    "- Traffic patterns (spikes can be injected)\n",
    "- Timestamps (can be faked by the sender)\n",
    "- Ordering (not guaranteed by standard queues)\n",
    "\n",
    "> **Your Turn:** Write a function called `safe_count(events)` that takes a list of\n",
    "> events and returns a count that handles duplicates. Use the idempotent pattern\n",
    "> from Section 4."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR TURN: Implement safe_count\n",
    "# This should return the number of UNIQUE events (deduplicated by event_id).\n",
    "\n",
    "def safe_count(events):\n",
    "    # --- YOUR CODE HERE ---\n",
    "    pass\n",
    "\n",
    "# Test it:\n",
    "if safe_count is not None:\n",
    "    result = safe_count(chaos_events)\n",
    "    print(f\"Raw count:  {len(chaos_events)}\")\n",
    "    print(f\"Safe count: {result}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7: Multiple Auditors â€” Who Is Right?\n",
    "\n",
    "If one auditor can miss events, get duplicates, or see inflated traffic,\n",
    "perhaps the answer is **more auditors**. If three independent observers\n",
    "each count the same events, you can compare their results.\n",
    "\n",
    "Our system has three auditor queues â€” A, B, and C â€” all subscribed to\n",
    "the same topic. Let's see what each one saw and whether they agree."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 7: Read from all three auditor queues\n",
    "\n",
    "auditor_results = {}\n",
    "\n",
    "for name, url in AUDITOR_QUEUES.items():\n",
    "    events = receive_all(url, max_total=200, timeout=15)\n",
    "    event_ids = {e.get(\"event_id\") for e in events}\n",
    "    auditor_results[name] = {\n",
    "        \"events\": events,\n",
    "        \"event_ids\": event_ids,\n",
    "        \"count\": len(events),\n",
    "        \"unique\": len(event_ids),\n",
    "        \"hosts\": count_by(events, \"host_id\"),\n",
    "    }\n",
    "    print(f\"{name}: {len(events)} messages, {len(event_ids)} unique\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 7: Do they agree?\n",
    "\n",
    "print(\"\\n--- Agreement Check ---\\n\")\n",
    "\n",
    "# Event ID overlap\n",
    "all_ids = [d[\"event_ids\"] for d in auditor_results.values()]\n",
    "common = all_ids[0]\n",
    "for ids in all_ids[1:]:\n",
    "    common = common & ids\n",
    "\n",
    "union = set()\n",
    "for ids in all_ids:\n",
    "    union |= ids\n",
    "\n",
    "print(f\"Events ALL three saw:    {len(common)}\")\n",
    "print(f\"Events at least one saw: {len(union)}\")\n",
    "if len(common) != len(union):\n",
    "    print(f\"Events NOT seen by all:  {len(union) - len(common)}\")\n",
    "    print(\"  --> Some auditors missed events that others saw!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 7: Per-host comparison\n",
    "\n",
    "print(\"\\n--- Per-Host Counts by Auditor ---\\n\")\n",
    "\n",
    "all_hosts = set()\n",
    "for d in auditor_results.values():\n",
    "    all_hosts.update(d[\"hosts\"].keys())\n",
    "\n",
    "names = list(auditor_results.keys())\n",
    "header = f\"  {'Host':25s}\" + \"\".join(f\"{n:>12s}\" for n in names) + \"   Agree?\"\n",
    "print(header)\n",
    "print(\"  \" + \"-\" * (len(header) - 2))\n",
    "\n",
    "for host in sorted(all_hosts):\n",
    "    counts = [auditor_results[n][\"hosts\"].get(host, 0) for n in names]\n",
    "    agree = \"YES\" if len(set(counts)) == 1 else \"NO\"\n",
    "    row = f\"  {host:25s}\" + \"\".join(f\"{c:12d}\" for c in counts) + f\"   {agree}\"\n",
    "    print(row)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Section 7: Majority vote\n",
    "\n",
    "print(\"\\n--- Majority Vote ---\\n\")\n",
    "print(\"When auditors disagree, we take the majority.\\n\")\n",
    "\n",
    "for host in sorted(all_hosts):\n",
    "    counts = [auditor_results[n][\"hosts\"].get(host, 0) for n in names]\n",
    "    vote = Counter(counts).most_common(1)[0]\n",
    "    print(f\"  {host:25s}: majority says {vote[0]:4d} views ({vote[1]}/3 agree)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bridge\n",
    "\n",
    "Right now, these three auditors are **SQS queues**. They have no relationship\n",
    "with each other. They do not know the others exist. They do not communicate\n",
    "or compare notes.\n",
    "\n",
    "The majority vote happened in **your code**. You were the authority who\n",
    "compared them and decided the answer.\n",
    "\n",
    "But in the 2032 system, there is no central authority. Nobody runs YOUR code\n",
    "on behalf of everyone. Each host, each auditor, each node in the network\n",
    "needs to be able to:\n",
    "\n",
    "1. **Discover** other nodes without a central registry\n",
    "2. **Communicate** directly with peers\n",
    "3. **Agree** on view counts without anyone being \"in charge\"\n",
    "\n",
    "That is **peer-to-peer**. That is the next phase.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Pub/Sub Lab.**\n",
    "You have seen queues, pub/sub, fan-out, ViewEvents, unreliable messaging,\n",
    "chaos detection, multi-auditor comparison, and majority voting.\n",
    "\n",
    "The question you should be asking now:\n",
    "*What if the auditors could talk to each other?*"
   ]
  }
 ]
}
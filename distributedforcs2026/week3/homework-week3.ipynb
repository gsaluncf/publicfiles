{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Week 3 Homework — Processes, Threads, and Concurrency\n",
    "\n",
    "Instructions:\n",
    "- Implement and analyze a thread pool processing pipeline.\n",
    "- Provide code, outputs, and concise analysis for each task.\n",
    "- Use Python 3.9+.\n",
    "\n",
    "Grading focuses on correctness, safe concurrency, sensible measurement, and clarity of interpretation.\n",
    "\n",
    "---"
   ],
   "id": "751b9da307c1dce0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1 — Build a configurable thread pool manager\n",
    "Implement a `ThreadPool` with:\n",
    "- Fixed number of worker threads\n",
    "- Bounded queue for tasks (configurable capacity)\n",
    "- `submit(fn, *args, **kwargs)` to enqueue work\n",
    "- `shutdown(wait=True)` for graceful termination\n",
    "\n",
    "Demonstrate submitting 1000 no-op tasks and waiting for completion.\n"
   ],
   "id": "68eb85001154c25d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import threading, queue, time\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ThreadPool:\n",
    "    def __init__(self, workers: int = 4, max_queue: int = 100):\n",
    "        self.tasks = queue.Queue(maxsize=max_queue)\n",
    "        self.workers = []\n",
    "        self.running = True\n",
    "        for _ in range(workers):\n",
    "            t = threading.Thread(target=self._worker, daemon=True)\n",
    "            t.start()\n",
    "            self.workers.append(t)\n",
    "\n",
    "    def _worker(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                fn, args, kwargs = self.tasks.get(timeout=0.2)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                fn(*args, **kwargs)\n",
    "            finally:\n",
    "                self.tasks.task_done()\n",
    "\n",
    "    def submit(self, fn: Callable, *args, **kwargs):\n",
    "        self.tasks.put((fn, args, kwargs))\n",
    "\n",
    "    def shutdown(self, wait=True):\n",
    "        self.running = False\n",
    "        if wait:\n",
    "            for t in self.workers:\n",
    "                t.join(timeout=1)\n",
    "\n",
    "# Demo\n",
    "pool = ThreadPool(workers=4, max_queue=50)\n",
    "for _ in range(1000):\n",
    "    pool.submit(lambda: None)\n",
    "pool.tasks.join()\n",
    "pool.shutdown()\n",
    "print('Task 1: OK')\n"
   ],
   "id": "497dfcf7bf7e78cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2 — Measure I/O-bound throughput and latency vs thread count\n",
    "Simulate an I/O-bound workload using `time.sleep()` to represent external waits.\n",
    "\n",
    "Procedure:\n",
    "- For thread counts: 1, 2, 4, 8, 16\n",
    "- Enqueue 2000 tasks, each sleeping an exponentially distributed delay with mean 5 ms\n",
    "- Measure: total time, throughput (tasks/sec), and average per-task service time\n",
    "\n",
    "Report the results in a small table or printed dicts and briefly interpret scaling behavior.\n"
   ],
   "id": "43a7060ec091c409"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.total = 0.0\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def record(self, dt):\n",
    "        with self.lock:\n",
    "            self.count += 1\n",
    "            self.total += dt\n",
    "\n",
    "\n",
    "def io_task(metrics: Metrics, mean_ms=5.0):\n",
    "    t0 = time.perf_counter()\n",
    "    time.sleep(random.expovariate(1.0/mean_ms) / 1000.0)\n",
    "    metrics.record(time.perf_counter() - t0)\n",
    "\n",
    "\n",
    "def bench_io(workers_list=(1,2,4,8,16), tasks=2000, mean_ms=5.0):\n",
    "    results = []\n",
    "    for w in workers_list:\n",
    "        pool = ThreadPool(workers=w)\n",
    "        m = Metrics()\n",
    "        t0 = time.perf_counter()\n",
    "        for _ in range(tasks):\n",
    "            pool.submit(io_task, m, mean_ms)\n",
    "        pool.tasks.join()\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        pool.shutdown()\n",
    "        avg_ms = (m.total/m.count)*1e3 if m.count else 0\n",
    "        results.append({'workers': w, 'elapsed_s': elapsed, 'throughput_rps': tasks/elapsed, 'avg_ms': avg_ms})\n",
    "    return results\n",
    "\n",
    "for r in bench_io():\n",
    "    print(r)\n"
   ],
   "id": "85e4099ab9e2d239"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Analysis (Task 2)\n",
    "Write 3–6 sentences:\n",
    "- How does throughput change with thread count? Where do returns diminish and why?\n",
    "- Why doesn’t average per-task service time change much across thread counts?\n",
    "\n",
    "---"
   ],
   "id": "6c278418d9e28cd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3 — Queueing and backpressure\n",
    "Set the queue capacity to a small value (e.g., 10). Measure enqueue wait time when producing faster than workers can consume.\n",
    "\n",
    "Implementation hints:\n",
    "- Measure time spent inside `submit` (waiting for a free slot)\n",
    "- Run with workers=2, tasks=1000, mean sleep ≈ 5 ms\n",
    "- Report total enqueue wait time and p50/p95 enqueue wait (if you collect samples)\n"
   ],
   "id": "33cbdff618325f0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statistics\n",
    "\n",
    "def bench_backpressure(workers=2, max_queue=10, tasks=1000, mean_ms=5.0):\n",
    "    pool = ThreadPool(workers=workers, max_queue=max_queue)\n",
    "    enqueue_waits = []\n",
    "\n",
    "    def task():\n",
    "        time.sleep(random.expovariate(1.0/mean_ms) / 1000.0)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(tasks):\n",
    "        s0 = time.perf_counter()\n",
    "        pool.submit(task)\n",
    "        enqueue_waits.append(time.perf_counter() - s0)\n",
    "    pool.tasks.join()\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    pool.shutdown()\n",
    "\n",
    "    waits_ms = [w*1e3 for w in enqueue_waits]\n",
    "    waits_ms.sort()\n",
    "    p50 = waits_ms[int(0.5*(len(waits_ms)-1))]\n",
    "    p95 = waits_ms[int(0.95*(len(waits_ms)-1))]\n",
    "    return {'elapsed_s': elapsed, 'total_enqueue_wait_s': sum(enqueue_waits), 'p50_enqueue_ms': p50, 'p95_enqueue_ms': p95}\n",
    "\n",
    "print(bench_backpressure())\n"
   ],
   "id": "4188fcca6adc22f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Analysis (Task 3)\n",
    "Explain how bounded queues implement backpressure and why enqueue wait grows when producers outrun consumers.\n",
    "\n",
    "---"
   ],
   "id": "ca0a39de7289321d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4 — CPU-bound caution (thought + optional code)\n",
    "Explain why Python threads provide limited speedup for CPU-bound loops (the GIL). Optionally, write a short experiment comparing threads vs `multiprocessing` for a CPU task.\n",
    "\n",
    "Write 4–8 sentences and include code if you run the comparison.\n"
   ],
   "id": "221693ca6eb24ca6"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

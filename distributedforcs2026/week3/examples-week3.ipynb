{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Week 3 Examples â€” Processes, Threads, and Concurrency\n",
    "\n",
    "This notebook demonstrates building a simple thread pool, benchmarking I/O-bound vs CPU-bound workloads, and observing contention and saturation.\n",
    "\n",
    "Python note: The GIL limits CPU-bound threading speedups; use multiprocessing for parallel CPU-bound tasks. Threads work well for overlapping I/O.\n",
    "\n",
    "---"
   ],
   "id": "5ea1f36148f32c27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A minimal thread pool with a work queue\n",
    "We implement:\n",
    "- `ThreadPool(workers)` with `submit(fn, *args, **kwargs)`\n",
    "- Graceful shutdown via `shutdown(wait=True)`\n",
    "- A bounded queue to provide backpressure\n"
   ],
   "id": "db3de8ff57252d28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import threading, queue, time, math, random\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ThreadPool:\n",
    "    def __init__(self, workers: int = 4, max_queue: int = 100):\n",
    "        self.tasks = queue.Queue(maxsize=max_queue)\n",
    "        self.workers = []\n",
    "        self.running = True\n",
    "        for _ in range(workers):\n",
    "            t = threading.Thread(target=self._worker, daemon=True)\n",
    "            t.start()\n",
    "            self.workers.append(t)\n",
    "\n",
    "    def _worker(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                fn, args, kwargs = self.tasks.get(timeout=0.2)\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            try:\n",
    "                fn(*args, **kwargs)\n",
    "            finally:\n",
    "                self.tasks.task_done()\n",
    "\n",
    "    def submit(self, fn: Callable, *args, **kwargs):\n",
    "        self.tasks.put((fn, args, kwargs))\n",
    "\n",
    "    def shutdown(self, wait=True):\n",
    "        self.running = False\n",
    "        if wait:\n",
    "            for t in self.workers:\n",
    "                t.join(timeout=1)\n"
   ],
   "id": "ae1a4b256fa5e5d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## I/O-bound workload simulation\n",
    "We simulate I/O by sleeping a random amount; threads can overlap waiting.\n"
   ],
   "id": "e54c8b164f4240f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.lock = threading.Lock()\n",
    "        self.count = 0\n",
    "        self.total = 0.0\n",
    "        self.samples = []\n",
    "\n",
    "    def record(self, dt):\n",
    "        with self.lock:\n",
    "            self.count += 1\n",
    "            self.total += dt\n",
    "            self.samples.append(dt)\n",
    "\n",
    "\n",
    "def io_task(metrics: Metrics, mean_ms=5.0):\n",
    "    t0 = time.perf_counter()\n",
    "    # Exponential-ish sleep distribution\n",
    "    delay = random.expovariate(1.0/mean_ms) / 1000.0\n",
    "    time.sleep(delay)\n",
    "    metrics.record(time.perf_counter() - t0)\n",
    "\n",
    "\n",
    "def run_benchmark_io(workers_list=(1,2,4,8,16), tasks=2000, mean_ms=5.0):\n",
    "    results = []\n",
    "    for w in workers_list:\n",
    "        pool = ThreadPool(workers=w)\n",
    "        m = Metrics()\n",
    "        t0 = time.perf_counter()\n",
    "        for _ in range(tasks):\n",
    "            pool.submit(io_task, m, mean_ms)\n",
    "        pool.tasks.join()\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        pool.shutdown()\n",
    "        avg_ms = (m.total/m.count)*1e3 if m.count else 0\n",
    "        results.append({\n",
    "            'workers': w,\n",
    "            'tasks': tasks,\n",
    "            'elapsed_s': elapsed,\n",
    "            'throughput_rps': tasks/elapsed,\n",
    "            'avg_service_ms': avg_ms,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "io_results = run_benchmark_io()\n",
    "for r in io_results:\n",
    "    print(r)\n"
   ],
   "id": "bd54a6f56bf573a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CPU-bound workload caveat (GIL)\n",
    "This simulates CPU work with a tight loop. Expect limited speedup with more threads due to the GIL. Consider `multiprocessing` for true CPU parallelism.\n"
   ],
   "id": "2197d6a886fe2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cpu_task(metrics: Metrics, n=1500000):\n",
    "    t0 = time.perf_counter()\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += (i % 7)\n",
    "    metrics.record(time.perf_counter() - t0)\n",
    "    return s\n",
    "\n",
    "\n",
    "def run_benchmark_cpu(workers_list=(1,2,4), tasks=12, n=800000):\n",
    "    results = []\n",
    "    for w in workers_list:\n",
    "        pool = ThreadPool(workers=w)\n",
    "        m = Metrics()\n",
    "        t0 = time.perf_counter()\n",
    "        for _ in range(tasks):\n",
    "            pool.submit(cpu_task, m, n)\n",
    "        pool.tasks.join()\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        pool.shutdown()\n",
    "        avg_ms = (m.total/m.count)*1e3 if m.count else 0\n",
    "        results.append({\n",
    "            'workers': w,\n",
    "            'tasks': tasks,\n",
    "            'elapsed_s': elapsed,\n",
    "            'throughput_rps': tasks/elapsed,\n",
    "            'avg_service_ms': avg_ms,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "cpu_results = run_benchmark_cpu()\n",
    "for r in cpu_results:\n",
    "    print(r)\n"
   ],
   "id": "6e5327be4ce0e02d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercises\n",
    "1) Add a bounded queue and demonstrate backpressure by making it small (e.g., 10). Measure enqueue wait time.\\\n",
    "2) Add per-task timestamps to compute queue wait vs service time percentiles.\\\n",
    "3) Replace CPU threads with a `multiprocessing.Pool` and compare results.\n"
   ],
   "id": "21c102ed8a81bfdf"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

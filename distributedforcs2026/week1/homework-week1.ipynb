{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Week 1 Homework — Time, Clocks, and Latency\n",
    "\n",
    "This homework is fully guided. Follow the numbered steps. If you have never measured latency before, don't worry—each task includes starter code, definitions, and self-checks.\n",
    "\n",
    "- Time on task: 90–120 minutes\n",
    "- Tools: Python 3.9+ (3.10+ recommended), standard library, matplotlib (optional for plots)\n",
    "- How to run: In VS Code or Jupyter, run cells from top to bottom. Re-run a cell with Shift+Enter.\n",
    "- What to submit: This completed notebook with your code, plots (or printed stats), and short written answers.\n",
    "\n",
    "Submission checklist:\n",
    "- [ ] All code cells run without errors top-to-bottom\n",
    "- [ ] You reported p50, p95, p99, and max for Task 1\n",
    "- [ ] You included at least one plot (histogram or CDF) in Task 1 (textual stats acceptable if plotting unavailable)\n",
    "- [ ] You computed clock skew over time and proposed a correction plan in Task 2\n",
    "- [ ] You answered the fan-out questions in Task 3 and, if you choose, ran the optional simulation\n",
    "\n",
    "Grading rubric (10 pts total):\n",
    "- Task 1 methodology and results (4 pts): warm-up (1), sample size ≥ 5,000 (1), correct percentiles (1), interpretation of tails (1)\n",
    "- Task 2 drift simulation and proposal (3 pts): correct skew computation (1), threshold reasoning (1), correction strategy clarity (1)\n",
    "- Task 3 tail latency reasoning (3 pts): correct intuition (1), two mitigations with trade-offs (2)\n",
    "\n",
    "---"
   ],
   "id": "c3cad0039333adf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 0 — Setup (read then run)\n",
    "We will optionally use `matplotlib` for plots. If it is not installed, the code will fall back to text-only output.\n",
    "\n",
    "- If you cannot install packages, you can still complete the assignment using printed summary statistics.\n",
    "- If you can install packages: in a terminal, run `pip install matplotlib` once.\n",
    "\n",
    "Run the cell below to set up helpers and imports.\n"
   ],
   "id": "a1cfea56b89d3cb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math, time, json, statistics, random, sys\n",
    "\n",
    "# Try to import matplotlib; continue without it if unavailable\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAVE_MPL = True\n",
    "except Exception as e:\n",
    "    HAVE_MPL = False\n",
    "    print(\"matplotlib not available; proceeding without plots.\")\n",
    "\n",
    "# Utility: percentile by index on a sorted list\n",
    "def percentile(sorted_values, q):\n",
    "    \"\"\"Return the q percentile (0..100) from a pre-sorted list using nearest-rank index.\"\"\"\n",
    "    if not sorted_values:\n",
    "        return float('nan')\n",
    "    q = max(0, min(100, q))\n",
    "    idx = int(round((q/100) * (len(sorted_values)-1)))\n",
    "    return sorted_values[idx]\n"
   ],
   "id": "232fbc3dc5876a0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1 — Measure a local latency distribution (guided)\n",
    "Goal: Measure the time to perform a simple local operation thousands of times and examine its distribution, especially the tail (p95/p99).\n",
    "\n",
    "What is latency? The time to complete one operation. We will measure in milliseconds (ms). Tails (p95/p99) show the slower end of the distribution.\n",
    "\n",
    "Step 1: Choose an operation (pick one):\n",
    "- JSON encode+decode a small object (default)\n",
    "- Concatenate small strings\n",
    "- Sum a Python list of small integers (already in memory)\n",
    "\n",
    "Run the next cell to define the operation and perform a short warm-up.\n"
   ],
   "id": "82e4560915738c86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Choose operation by setting OPERATION = 'json' | 'str' | 'sum'\n",
    "OPERATION = 'json'  # change if you want\n",
    "\n",
    "obj = {\"a\": 1, \"b\": [i for i in range(50)], \"c\": \"x\"*128}\n",
    "nums = list(range(100))\n",
    "\n",
    "# Define the operation function\n",
    "if OPERATION == 'json':\n",
    "    def do_op():\n",
    "        s = json.dumps(obj)\n",
    "        json.loads(s)\n",
    "elif OPERATION == 'str':\n",
    "    def do_op():\n",
    "        s = \"\".join([\"a\" for _ in range(200)])\n",
    "else:  # 'sum'\n",
    "    def do_op():\n",
    "        sum(nums)\n",
    "\n",
    "# Warm-up: run operation without timing to prime caches and JIT-like effects\n",
    "for _ in range(500):\n",
    "    do_op()\n",
    "\n",
    "print(\"Warm-up complete.\")\n"
   ],
   "id": "da49469e583414ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Step 2: Collect N measurements using `time.perf_counter()` (a high-precision monotonic timer). Recommendations:\n",
    "- Use at least N = 5,000\n",
    "- Avoid other heavy processes while measuring\n",
    "- Remove outliers only if you can justify it (we will keep all samples here)\n",
    "\n",
    "Run the cell to measure and compute summary statistics.\n"
   ],
   "id": "b5d869c7b7425d89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "N = 6000  # at least 5000\n",
    "runs_s = []\n",
    "for _ in range(N):\n",
    "    t0 = time.perf_counter()\n",
    "    do_op()\n",
    "    runs_s.append(time.perf_counter() - t0)\n",
    "\n",
    "runs_ms = sorted([x * 1e3 for x in runs_s])\n",
    "\n",
    "summary = {\n",
    "    'count': len(runs_ms),\n",
    "    'p50_ms': percentile(runs_ms, 50),\n",
    "    'p95_ms': percentile(runs_ms, 95),\n",
    "    'p99_ms': percentile(runs_ms, 99),\n",
    "    'max_ms': max(runs_ms),\n",
    "    'mean_ms': statistics.fmean(runs_ms),\n",
    "}\n",
    "print(summary)\n",
    "\n",
    "# Self-checks\n",
    "assert len(runs_ms) >= 5000, \"Need at least 5,000 samples\"\n",
    "assert summary['p50_ms'] <= summary['max_ms'] + 1e-9\n"
   ],
   "id": "55724ab1b22f426c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Step 3 (optional but recommended): Visualize the distribution.\n",
    "- Histogram: shows frequency of latencies\n",
    "- CDF: shows the percentile curve; p95 is the value where 95% of samples are faster\n",
    "\n",
    "Run this cell. If `matplotlib` is unavailable, it will print text instead.\n"
   ],
   "id": "3e7555c9b1bd428a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if HAVE_MPL:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].hist(runs_ms, bins=50, color=\"#93c5fd\", edgecolor=\"#1e40af\")\n",
    "    axes[0].set_title(\"Latency Histogram (ms)\")\n",
    "    axes[0].set_xlabel(\"ms\"); axes[0].set_ylabel(\"count\")\n",
    "\n",
    "    # Empirical CDF\n",
    "    xs = runs_ms\n",
    "    ys = [i/(len(xs)-1) for i in range(len(xs))]\n",
    "    axes[1].plot(xs, ys, color=\"#1e40af\")\n",
    "    axes[1].axhline(0.95, color=\"#f59e0b\", linestyle='--', label='p95')\n",
    "    axes[1].axhline(0.99, color=\"#ef4444\", linestyle='--', label='p99')\n",
    "    axes[1].set_title(\"Latency CDF\"); axes[1].set_xlabel(\"ms\"); axes[1].set_ylabel(\"fraction ≤ x\")\n",
    "    axes[1].legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Plotting unavailable. Here are a few quantiles:\")\n",
    "    for q in (10, 25, 50, 75, 90, 95, 99):\n",
    "        print(f\"p{q}: {percentile(runs_ms, q):.4f} ms\")\n"
   ],
   "id": "875092e982b1dca1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write-up (Task 1)\n",
    "In 3–6 sentences:\n",
    "- Compare p50 to p95 and p99. Are the tails much higher? Why might that be on a single machine? (Think: cache misses, background processes, Python GC, CPU frequency scaling.)\n",
    "- If you repeated the experiment at a different time or on battery power, what might change and why?\n",
    "\n",
    "---"
   ],
   "id": "abddb3cf83f4c6bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2 — Simulate clock drift and propose a correction strategy\n",
    "Background: Real clocks are imperfect. Drift is how fast a clock runs vs. real time (parts-per-million, ppm). Two machines at +30 ppm and −40 ppm will diverge over time.\n",
    "\n",
    "Step 1: Simulate per-second advancement for one hour and record the skew (A − B).\n"
   ],
   "id": "c9f169c8a4f6731"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simulate_drift(seconds=3600, ppm_a=30, ppm_b=-40):\n",
    "    rate_a = 1 + ppm_a/1_000_000\n",
    "    rate_b = 1 + ppm_b/1_000_000\n",
    "    a = b = 0.0\n",
    "    skew = []  # seconds difference (A-B)\n",
    "    for _ in range(seconds):\n",
    "        a += rate_a\n",
    "        b += rate_b\n",
    "        skew.append(a - b)\n",
    "    return skew\n",
    "\n",
    "skew_s = simulate_drift()\n",
    "print(f\"Skew after 1 hour: {skew_s[-1]*1e3:.2f} ms\")\n",
    "print(f\"Max |skew| over the hour: {max(abs(x) for x in skew_s)*1e3:.2f} ms\")\n"
   ],
   "id": "bb4447c118a24ec6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 2 (optional plot): Visualize skew growth over time and find when it exceeds a threshold (e.g., 100 ms).\n",
   "id": "c1dbedb3d631ef06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "THRESHOLD_MS = 100.0\n",
    "if HAVE_MPL:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot([s*1e3 for s in skew_s], color=\"#1e40af\")\n",
    "    plt.axhline(THRESHOLD_MS, color=\"#ef4444\", linestyle='--', label='threshold')\n",
    "    plt.title(\"Clock Skew Over Time (ms)\")\n",
    "    plt.xlabel(\"seconds\"); plt.ylabel(\"ms\")\n",
    "    plt.legend(); plt.show()\n",
    "\n",
    "# Find first time skew exceeds threshold\n",
    "first_exceed = next((i for i, s in enumerate(skew_s) if abs(s*1e3) > THRESHOLD_MS), None)\n",
    "print(\"First exceed (s):\", first_exceed)\n"
   ],
   "id": "d64f5ef88cdaf963"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Step 3: Propose a correction plan. Consider:\n",
    "- Periodic synchronization interval based on how fast skew grows\n",
    "- Slewing (gradually adjusting rate) vs. stepping (jumping time) and their side-effects\n",
    "- Impact on timeouts, log ordering, and user-visible behavior\n",
    "\n",
    "### Write-up (Task 2)\n",
    "In 4–8 sentences: describe your plan and justify how it meets an SLA of <100 ms skew. Note trade-offs (e.g., frequent syncs = network overhead; slewing = temporary drift of timers).\n",
    "\n",
    "---"
   ],
   "id": "872a558ef0070f2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3 — Why p99 dominates in fan-out requests\n",
    "Scenario: A front-end makes 20 parallel calls. The page cannot render until all complete, so the slowest call often dictates user-perceived latency.\n",
    "\n",
    "Part A (reasoning): Explain why the maximum of many samples tends to be closer to the tail of the single-call distribution. Use your Task 1 stats.\n",
    "\n",
    "Part B (optional simulation): Sample from your empirical distribution, take the max of 20 calls per trial, and compare the resulting distribution to single-call latencies.\n"
   ],
   "id": "a9fc61758d174dee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Optional simulation of fan-out tails using empirical samples from Task 1\n",
    "TRIALS = 2000\n",
    "FANOUT = 20\n",
    "if 'runs_ms' in globals() and len(runs_ms) >= 1000:\n",
    "    import random\n",
    "    maxes = []\n",
    "    for _ in range(TRIALS):\n",
    "        picks = random.choices(runs_ms, k=FANOUT)\n",
    "        maxes.append(max(picks))\n",
    "    maxes.sort()\n",
    "    fanout_summary = {\n",
    "        'p50_max_ms': percentile(maxes, 50),\n",
    "        'p95_max_ms': percentile(maxes, 95),\n",
    "        'p99_max_ms': percentile(maxes, 99),\n",
    "    }\n",
    "    print(\"Fan-out (20 parallel) max latency stats:\", fanout_summary)\n",
    "    if HAVE_MPL:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.hist(maxes, bins=40, color=\"#93c5fd\", edgecolor=\"#1e40af\")\n",
    "        plt.title(\"Distribution of Max Latency (20 parallel calls)\")\n",
    "        plt.xlabel(\"ms\"); plt.ylabel(\"count\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Run Task 1 first to populate runs_ms, then re-run this cell.\")\n"
   ],
   "id": "1a0b57c35861e0cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write-up (Task 3)\n",
    "In 4–8 sentences: Explain why fan-out pushes you into the tail. Propose at least two mitigations and note trade-offs, e.g.,\n",
    "- Hedged requests (pros: reduces tail; cons: extra load)\n",
    "- Timeouts with fallback/caching (pros: better perceived latency; cons: possible stale data)\n",
    "- Prioritizing critical sub-requests or rendering progressively\n",
    "\n",
    "---"
   ],
   "id": "c32b0cef2a960b0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final reflection (optional, +0.5 pt bonus)\n",
    "1–3 sentences: One surprise from your measurements this week and one question you have for next week.\n"
   ],
   "id": "c11c3e85ba6e5fa6"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
